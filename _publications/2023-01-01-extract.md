---
title: "Extract: Explainable transparent control of bias in embeddings"
collection: publications
permalink: /publication/2023-01-01-extract
excerpt: 'A suite of methods for controlling bias in knowledge graph embeddings while maintaining model utility and transparency.'
date: 2023-01-01
venue: 'AEQUITAS 2023: AEQUITAS 2023 First AEQUITAS Workshop on Fairness and Bias in AI co-located with ECAI 2023'
citation: 'Z. Guo, Z. Xu, M. Lewis, and N. Cristianini, "Extract: Explainable transparent control of bias in embeddings," in AEQUITAS 2023: AEQUITAS 2023 First AEQUITAS Workshop on Fairness and Bias in AI co-located with ECAI 2023, 2023.'
---

This work addresses the challenge that knowledge-graph embeddings risked leaking protected attributes (e.g., gender, age, occupation) from behavioral data, raising privacy and fairness concerns.

**Abstract**: We developed EXTRACT, a suite of transparent methods for controlling bias in knowledge graph embeddings. The approach applies Canonical Correlation Analysis to pinpoint bias-leakage sources, decomposes embeddings into private-attribute vectors via linear-system solving, and integrates four transparent mitigation methods.

**Key Contributions**:
- EXTRACT suite for bias control in knowledge graph embeddings
- Canonical Correlation Analysis for bias-leakage detection
- Linear-system solving for embedding decomposition
- Four transparent mitigation methods
- Balance between model utility and privacy protection

**Methodology**:
- Engineered vector-based knowledge base construction
- Applied CCA to pinpoint bias-leakage sources
- Decomposed embeddings into private-attribute vectors
- Integrated transparent mitigation methods to strip unwanted signals

**Results**: Demonstrated robust recommending performance alongside bias control, highlighting the trade-off between accuracy and privacy.

**Applications**: Adapted bias-mitigation techniques to financial-entity embeddings, ensuring fair, regulatory-compliant representations for risk models and portfolio construction.

Recommended citation: Z. Guo, Z. Xu, M. Lewis, and N. Cristianini, "Extract: Explainable transparent control of bias in embeddings," in AEQUITAS 2023: AEQUITAS 2023 First AEQUITAS Workshop on Fairness and Bias in AI co-located with ECAI 2023, 2023.